{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A2 Gibbs sampling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armandordorica/MIE1516_A2_Gibbs_sampling/blob/master/A2_Gibbs_sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcXpA-OCr8Ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "from scipy.stats import sem, t\n",
        "from scipy import mean\n",
        "import matplotlib.pyplot as plt\n",
        "# import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7QRNi06r_gf",
        "colab_type": "text"
      },
      "source": [
        "### Global Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VtiGwAmsBE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_confidence_interval(data): \n",
        "  confidence = 0.95\n",
        "\n",
        "  n = len(data)\n",
        "  mean = np.mean(data)\n",
        "  std_err = sem(data)\n",
        "  h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
        "\n",
        "  start = mean - h\n",
        "  end = mean + h\n",
        "\n",
        "  return start, mean, end\n",
        "# Sample variable from list of dataframes \n",
        "def list_of_dicts_to_df(list_of_dicts):\n",
        "  df = None\n",
        "  df = dictionary_to_df(list_of_dicts[0])\n",
        "  for i in range(1, len(list_of_dicts)):\n",
        "    df2 = dictionary_to_df(list_of_dicts[i])\n",
        "    df = pd.concat([df, df2], ignore_index=True, sort=False)\n",
        "  return df\n",
        "\n",
        "def sample_var_from_list_of_dfs(my_list_of_dfs, var_to_sample):\n",
        "  \"\"\"\n",
        "  Input: Expects a list of dataframes that will contain var_to_sample \n",
        "  Output: Returns a viable value for the sampling of this variable \n",
        "  \"\"\"\n",
        "  list_of_assoc_dfs = dfs_that_contain_var(my_list_of_dfs, var_to_sample)\n",
        "  value = sample_value_from_simple_df(list_of_assoc_dfs[0][[var_to_sample, 'Pr']])\n",
        "  return value\n",
        "\n",
        "def dfs_that_contain_var(list_of_dfs, var_to_sample):\n",
        "  ### Given a list of dfs, return a list of the ones that contain a variable \n",
        "  list_of_assoc_dfs = []\n",
        "  restricted_list_of_dfs = list_of_dfs\n",
        "  for i in range(0, len(restricted_list_of_dfs)):\n",
        "    #print(list(restricted_list_of_dfs[i].columns))\n",
        "    if var_to_sample in list(restricted_list_of_dfs[i].columns):\n",
        "      #print(\"{} is in df with {}\".format(var_to_sample,list(restricted_list_of_dfs[i].columns) ))\n",
        "      list_of_assoc_dfs.append(restricted_list_of_dfs[i])\n",
        "  return list_of_assoc_dfs\n",
        "\n",
        "def update_dict_to_sample(dict_of_evidences, var_to_sample): \n",
        "  my_dict = dict_of_evidences.copy()\n",
        "  del my_dict[var_to_sample]\n",
        "  return my_dict\n",
        "\n",
        "def restrict_list_of_dfs(list_of_dfs, list_of_vars, dict_of_evidences): \n",
        "  \"\"\"\n",
        "  Input: Given a list of dataframes, a dictionary of evidences, and a list of variables\n",
        "  Output: Return a list of dataframes with those conditions applied as listed in the dictionary \n",
        "  \"\"\"\n",
        "  #print(\"Restricting list of dataframes...\")\n",
        "  new_dfs_list = list_of_dfs.copy()\n",
        "  for u in range(0, len(list_of_vars)):\n",
        "    var = list_of_vars[u]\n",
        "    value = dict_of_evidences[var]\n",
        "    for i in range(0, len(list_of_dfs)):\n",
        "      if var_in_df(list_of_dfs[i], var): \n",
        "        #print(list_of_dfs[i])\n",
        "        #print(\"contains var: {}\".format(var))\n",
        "        new_dfs_list[i] = set_df_to_restriction(new_dfs_list[i], var, value)\n",
        "        #print(\"setting restriction {} = {} on {}\".format(var, value, new_dfs_list[i]))\n",
        "\n",
        "  return new_dfs_list\n",
        "\n",
        "def var_in_df(df, var): \n",
        "  return var in list(df.columns)\n",
        "\n",
        "def set_df_to_restriction(df, var, value):\n",
        "  df = df[df[var]==value]\n",
        "  return df\n",
        "\n",
        "def cpd_list_to_df_list(list_of_cpds):\n",
        "  dfs_list = []\n",
        "  for i in range(0, len(list_of_cpds)):\n",
        "    dfs_list.append(list_of_cpds[i].to_truth_table())\n",
        "  return dfs_list \n",
        "\n",
        "def set_cpds_to_state(cpd_list, var, value):\n",
        "  \"\"\"\n",
        "  Input: Given a list of CPDs, a variable, and a value \n",
        "  Output: Return a list of cpds with the applied restriction\n",
        "  \"\"\"\n",
        "  new_list = []\n",
        "  for i in range(0, len(cpd_list)):\n",
        "    if len(list(cpd_list[i].to_truth_table()['Pr']))>2:\n",
        "      print(cpd_list[i].to_truth_table())\n",
        "      if  cpd_list[i].contains_var(var):\n",
        "        print(\"i:{}\".format(i))\n",
        "        new_item = replace_cpd_with_restriction(cpd_list[i], var, value)\n",
        "        new_list.append(new_item)\n",
        "      else:\n",
        "        new_list.append(cpd_list[i])\n",
        "    else: \n",
        "      new_list.append(cpd_list[i])\n",
        "  return new_list \n",
        "\n",
        "def construct_trees(edges):\n",
        "    \"\"\"Given a list of edges [child, parent], return trees. \"\"\"\n",
        "    trees = collections.defaultdict(dict)\n",
        "\n",
        "    for child, parent in edges:\n",
        "        trees[parent][child] = trees[child]\n",
        "\n",
        "    # Find roots\n",
        "    children, parents = zip(*edges)\n",
        "    roots = set(parents).difference(children)\n",
        "\n",
        "    return {root: trees[root] for root in roots}\n",
        "\n",
        "\n",
        "def dictionary_to_df(mydict):\n",
        "  \"\"\"\n",
        "  Input: Gets a dictonary of the form {'O1': 1, 'O2': 0, 'O3': 1, 'S1': 0, 'S2': 1, 'S3': 1}\n",
        "  Output: A dataframe to represent it \n",
        "  \"\"\"\n",
        "  d = mydict.copy()\n",
        "  keys = list(d.keys())\n",
        "  for i in range(0, len(keys)):\n",
        "    #print(keys[i])\n",
        "    d[str(keys[i])] = [d[str(keys[i])]]\n",
        "\n",
        "  df = pd.DataFrame.from_dict(d)\n",
        "  cols = list(df.columns)\n",
        "  cols.sort(reverse=True)\n",
        "  df = df[cols]\n",
        "\n",
        "  return df\n",
        "\n",
        "def sample_value_from_simple_df(df):\n",
        "  \"\"\"\n",
        "  Input: A dataframe with only one variable column and one Pr column\n",
        "  Output: A value between 1 and 0 based on the probability of sampling \n",
        "  \"\"\"\n",
        "  var = pop_string_from_list(list(df.columns), 'Pr')[0]\n",
        "  n=1\n",
        "  if (1 in list(df[var])) and (0 in list(df[var])): #sample only if there are 1s and zeros to sample from\n",
        "    p = float(df[df[var]==1]['Pr'])\n",
        "    s = np.random.binomial(n, p, 1)\n",
        "    #print(\"Sample returns {} = {}\".format(var, s[0]))\n",
        "    return s[0]\n",
        "  else:\n",
        "    return list(df[var])[0]\n",
        "\n",
        "def df_normalize(df):\n",
        "  \"\"\"\n",
        "  Input: Dataframe with probabilities\n",
        "  Output: Dataframe with probabilities that add up to 1 \n",
        "  \"\"\"\n",
        "  df['Pr']= df['Pr'].div(df['Pr'].sum())\n",
        "  return df \n",
        "\n",
        "def replace_cpd_with_restriction(cpd, column_name, restriction_value):\n",
        "  \"\"\"\n",
        "  input: a cpd and a restriction on a column name equal to the value \n",
        "  output: a new cpd with that restriction applied \n",
        "  \"\"\"\n",
        "  # 'S1' in list(infer.cpds_to_multiply[0].to_truth_table().columns)\n",
        "  df = cpd.to_truth_table()\n",
        "  if column_name in list(df.columns):\n",
        "    df = df[df[column_name] == restriction_value]\n",
        "    df = remove_irrelevant_variable(df)\n",
        "  try: \n",
        "    df=df_to_cpd(df)\n",
        "    return df\n",
        "  except: \n",
        "    return df \n",
        "\n",
        "\n",
        "def replace_evidence_with_restriction_gibbs(list_of_factors, dict_of_evidences):\n",
        "  \"\"\"\n",
        "  Input: List of factors (tabular cpds), Dictionary containing keys as the \n",
        "  variable name and the random value for restriction\n",
        "\n",
        "  Output: new list of factors with the replaced restrictions \n",
        "  \"\"\"\n",
        "  print(\"iterating through each of the list_of_factors \")\n",
        "  new_factors_list = []\n",
        "  for i in range(0, len(list_of_factors)):\n",
        "    df = list_of_factors[i].to_truth_table()\n",
        "    cpd_vars = list(df.columns)\n",
        "    cpd_vars = pop_string_from_list(cpd_vars, 'Pr')\n",
        "    print(\"Replacing evidence with restriction for cpd that contains {}\".format(cpd_vars))\n",
        "\n",
        "    for j in range(0, len(cpd_vars)):\n",
        "      # print(\"restricting on variable {}\".format(cpd_vars[i]))\n",
        "      print(\"cpd_vars[j] = {}\".format(cpd_vars[j]))\n",
        "      print(\"dict_of_evidences = {}\".format(dict_of_evidences))\n",
        "      this_restriction = dict_of_evidences[cpd_vars[j]]\n",
        "      print(\"restricting on variable {} = {}\".format(cpd_vars[j], this_restriction))\n",
        "      df = df[df[cpd_vars[j]]==this_restriction]\n",
        "      print(df)\n",
        "    # df = df_to_cpd(df)\n",
        "    new_factors_list.append(df)\n",
        "\n",
        "  return new_factors_list\n",
        "\n",
        "def pop_string_from_list(mylist, mystring):\n",
        "  \"\"\"\n",
        "  Input: List of strings,  a string to remove \n",
        "  Output: Returns the list with the string removed\n",
        "  \"\"\"\n",
        "  index = mylist.index(str(mystring))\n",
        "  mylist.pop(index)\n",
        "  return mylist\n",
        "\n",
        "def remove_irrelevant_variable(df):\n",
        "  \"\"\"\n",
        "  If a dataframe has a column of just 1s, i.e. evidence has been observed then \n",
        "  remove those columns from tabular representation\n",
        "  \"\"\"\n",
        "  list(df.columns).pop(-1)\n",
        "  vars = list(df.columns)\n",
        "  vars.pop(-1)\n",
        "\n",
        "  indices_to_pop = []\n",
        "\n",
        "  for i in range(0, len(vars)):\n",
        "    # print(i)\n",
        "    # print(str(vars[i]))\n",
        "    # print(df[str(vars[i])])\n",
        "    if df[str(vars[i])].sum() == df[str(vars[i])].count(): #if there's a column of 1s \n",
        "      #print(\"There's a column of 1s for variable {}\".format(vars[i]))\n",
        "      #print(\"Removing {}\".format(str(vars[i])))\n",
        "      indices_to_pop.append(i)\n",
        "\n",
        "  for j in range(0, len(vars)):\n",
        "    print(j)\n",
        "    print(str(vars[j]))\n",
        "    print(df[str(vars[j])])\n",
        "    if len(df.index)>1: # Only remove there's more than one row in the dataframe\n",
        "      if (df[vars[j]]==0).astype(int).sum() == df[str(vars[j])].count(): ## if there's a column of zeros \n",
        "        #print(\"There's a column of 0s for variable {}\".format(vars[j]))\n",
        "        #print(\"Removing {}\".format(str(vars[j])))\n",
        "        indices_to_pop.append(j)\n",
        "\n",
        "  for i in range(len(indices_to_pop)):\n",
        "    vars.pop(indices_to_pop[i])\n",
        "\n",
        "\n",
        "  vars.append(\"Pr\")\n",
        "  df[vars]\n",
        "  return df[vars]\n",
        "\n",
        "def df_to_cpd(df):\n",
        "  df = remove_irrelevant_variable(df)\n",
        "  vars = list(df.columns)\n",
        "  vars.pop(-1)\n",
        "  vars = vars[0]\n",
        "  variable_card = len(list(df.T.columns))\n",
        "  values = list(df['Pr'])\n",
        "  df_cpd = TabularCPD(variable=vars, variable_card=variable_card, values=[values])\n",
        "  return df_cpd\n",
        "\n",
        "def delete_df_from_list(factors_list, df):\n",
        "  for i in range(0, len(factors_list)):\n",
        "    if isinstance(factors_list[i], pd.DataFrame):\n",
        "      print(\"found a dataframe\")\n",
        "      if factors_list[i].equals(df):\n",
        "        print(\"equal to my dataframe, remove from list \")\n",
        "        factors_list.pop(i)\n",
        "  return factors_list    \n",
        "\n",
        "def __eq__(node1, node2):\n",
        "    return node1.name==node2.name and node1.parents==node2.parents and node1.children==node2.children\n",
        "\n",
        "def object_in_list(object, list_of_objects):\n",
        "  for i in range(0, len(list_of_objects)):\n",
        "    if __eq__(object,list_of_objects[i]): \n",
        "      return True \n",
        "\n",
        "  return False\n",
        "\n",
        "\n",
        "def toggle(var):\n",
        "  if var == 0:\n",
        "    return 1\n",
        "  if var == 1:\n",
        "    return 0\n",
        "\n",
        "def boolean_truth_table(num_vars):\n",
        "  truth_table = []\n",
        "  num_vars = num_vars\n",
        "  num_cols = num_vars\n",
        "  var = 1\n",
        "  num_rows = 2**num_vars\n",
        "  for col_num in range(0,num_cols):\n",
        "    truth_table.append([])\n",
        "    col_num = col_num+1\n",
        "    # print(\"col: {} toggle every {} values\".format(col_num, 2**(num_vars-col_num)))\n",
        "    for row_num in range(0, num_rows):\n",
        "      if row_num%2**(num_vars-col_num)==0:\n",
        "        var = toggle(var)\n",
        "      truth_table[col_num-1].append(var)\n",
        "      # print(truth_table[col_num-1])\n",
        "      # print(var)\n",
        "  return truth_table\n",
        "\n",
        "def generate_truth_table(list_of_variables):\n",
        "  d = dict()\n",
        "  num_vars = len(list_of_variables)\n",
        "  for i in range(0, num_vars): \n",
        "    d[str(list_of_variables[i])] = boolean_truth_table(len(list_of_variables))[i]\n",
        "  df = pd.DataFrame(data=d)\n",
        "  return df\n",
        "\n",
        "def multiply_tabular_cpds(tabular_cpd1, tabular_cpd2, var_to_marginalize):\n",
        "  df1 = tabular_cpd1.to_pandas_df()\n",
        "  df1 = tabular_cpd1.to_pandas_df()\n",
        "\n",
        "  vars_factor_1 = tabular_cpd1.get_factor().vars_in_factor()\n",
        "  vars_factor_1.remove(var_to_marginalize)\n",
        "\n",
        "  vars_factor_2 = tabular_cpd2.get_factor().vars_in_factor()\n",
        "  vars_factor_2.remove(var_to_marginalize)\n",
        "\n",
        "  total_vars = []\n",
        "  total_vars.append(vars_factor_1[0])\n",
        "  total_vars.append(vars_factor_2[0])\n",
        "  output_table = generate_truth_table(total_vars) \n",
        "\n",
        "  vars_factor_1.append('Pr')\n",
        "  vars_factor_2.append('Pr')\n",
        "\n",
        "  result = pd.merge(df1, df2, on='B', how='inner')\n",
        "  r0 = result[result['B']==0].Pr_x*result[result['B']==0].Pr_y\n",
        "  r1 = (result[result['B']==1].Pr_x*result[result['B']==1].Pr_y).reset_index(drop=True)\n",
        "  output_table['Pr']= r0.add(r1, fill_value=0)\n",
        "  output_table\n",
        "  return output_table\n",
        "\n",
        "def multiply_tabular_cpds_v2(cpd_a, cpd_b):\n",
        "  \"\"\"\n",
        "  input: two tabular cpds which can be in either TabularCPD or dataframe format\n",
        "  output: dataframe which is the product of the two cpds multiplied by \n",
        "  their common term\n",
        "  \"\"\"\n",
        "  if isinstance(cpd_a, TabularCPD):\n",
        "    left = cpd_a.to_truth_table()\n",
        "  else: \n",
        "    left = cpd_a\n",
        "  if isinstance(cpd_b, TabularCPD):\n",
        "    right = cpd_b.to_truth_table()\n",
        "  else:\n",
        "    right = cpd_b\n",
        "  common_columns= np.intersect1d(left.columns, right.columns)\n",
        "  common_columns= list(common_columns)\n",
        "  common_columns.remove('Pr')\n",
        "  result = pd.merge(left, right, on=common_columns, how='inner')\n",
        "  result['Pr']=result['Pr_x'] *result['Pr_y']\n",
        "  return result.drop(columns=['Pr_x', 'Pr_y'])\n",
        "\n",
        "def df_marginalize(df, vars_to_marginalize):\n",
        "  \"\"\"\n",
        "  input: a dataframe in truth table format with a \"Pr\" column - typically an output of `multiply_tabular_cpds_v2`\n",
        "        , a list of variables to marginalize on \n",
        "  output: a dataframe with the removed column that you marginalized on\n",
        "  \"\"\"\n",
        "  if isinstance(df, TabularCPD):\n",
        "    df = df.to_truth_table()\n",
        "    df_columns = list(df.columns)\n",
        "    df_columns.remove('Pr')\n",
        "\n",
        "    l1 = df_columns\n",
        "    l2 = vars_to_marginalize\n",
        "    l3 = [x for x in l1 if x not in l2]\n",
        "    group_by_list = l3\n",
        "    if len(group_by_list)>0:\n",
        "      df = df.groupby(group_by_list).sum()\n",
        "      return df.drop(columns=vars_to_marginalize).reset_index() \n",
        "  if isinstance(df, pd.DataFrame):\n",
        "    df_columns = list(df.columns)\n",
        "    df_columns.remove('Pr')\n",
        "    l1 = df_columns\n",
        "    l2 = vars_to_marginalize\n",
        "    l3 = [x for x in l1 if x not in l2]\n",
        "    group_by_list = l3\n",
        "    if len(group_by_list)>0:\n",
        "      df = df.groupby(group_by_list).sum()  \n",
        "      return df.drop(columns=vars_to_marginalize).reset_index() \n",
        "  else: \n",
        "    return df \n",
        "\n",
        "def recursive_multiplication(list_of_cpds):\n",
        "  product = None\n",
        "  for i in range(0, len(list_of_cpds)):\n",
        "    if i==0: \n",
        "      if isinstance(list_of_cpds[0], TabularCPD):\n",
        "        product = list_of_cpds[0].to_truth_table()\n",
        "      elif isinstance(list_of_cpds[0], pd.DataFrame):\n",
        "        product = list_of_cpds[0]\n",
        "    if i>0:\n",
        "      product = multiply_tabular_cpds_v2(product, list_of_cpds[i])\n",
        "  return product"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAfj7GY6sFbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Node:\n",
        "  def __init__(self, name, parents='', children=''):\n",
        "    self.name = name\n",
        "    self.parents = parents\n",
        "    self.children = children"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp7fSxASsImF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyBayesianModel: \n",
        "  def __init__(self, list_of_edges, nodes=[]):\n",
        "    self.list_of_edges = list(list_of_edges)\n",
        "    self.nodes = nodes # list(set([k for i in list_of_edges for k in i]))\n",
        "    self.tabular_cpds=[]\n",
        "    self.suggested_order=[]\n",
        "    \n",
        "\n",
        "  def get_suggested_order(self):\n",
        "    if len(self.suggested_order)==0:\n",
        "      variables = [''] *len(self.nodes)\n",
        "      parents = np.zeros(len(self.nodes))\n",
        "      children= np.zeros(len(self.nodes))\n",
        "\n",
        "      for i in range(0, len(self.nodes)):\n",
        "        variables[i]=self.nodes[i].name\n",
        "        parents[i]=len(self.nodes[i].parents)\n",
        "        children[i]=len(self.nodes[i].children)\n",
        "\n",
        "      df = pd.DataFrame(variables, columns =['Variables']) \n",
        "      df['Parents'] = parents\n",
        "      df['Children'] = children\n",
        "      df['Total'] = df['Parents']+df['Children']\n",
        "      suggested_order = list(df.sort_values(by=['Total'])['Variables'])\n",
        "      self.suggested_order = suggested_order \n",
        "      return suggested_order\n",
        "    else:\n",
        "      return self.suggested_order\n",
        "      \n",
        "#1 construct a factor for each conditional probability\n",
        "  def add_cpds(self, list_of_cpds):\n",
        "      for i in range(0, len(list_of_cpds)):\n",
        "        list_of_cpds[i].model = self\n",
        "        # while the model doesn't have the full list of cpds, keep appending\n",
        "        if (len(self.tabular_cpds) <= len(list_of_cpds)):\n",
        "          self.tabular_cpds.append(list_of_cpds[i])\n",
        "          edges_with_children=[item for item in list_of_cpds[i].model.list_of_edges if item[0] == list_of_cpds[i].variable]\n",
        "    \n",
        "        #adding nodes and parents to the model that it belongs to\n",
        "          if len(edges_with_children)>0: \n",
        "            list_of_cpds[i].model.nodes.append(Node(list_of_cpds[i].variable, \n",
        "                              list_of_cpds[i].evidence, \n",
        "                              [item for item in list_of_cpds[i].model.list_of_edges if item[0] == list_of_cpds[i].variable][0][1]))\n",
        "            \n",
        "          elif len(edges_with_children)==0: \n",
        "            list_of_cpds[i].model.nodes.append(Node(list_of_cpds[i].variable, \n",
        "                              list_of_cpds[i].evidence ))\n",
        "      self.dedupe_list_of_nodes()\n",
        "  \n",
        "  def dedupe_list_of_nodes(self):\n",
        "    ##starts with an empty list and only adds items to it if they don't exist in the list\n",
        "    empty_list=[]\n",
        "    for i in range(0, len(self.nodes)):\n",
        "      if not object_in_list(self.nodes[i], empty_list):\n",
        "        empty_list.append(self.nodes[i])\n",
        "    self.nodes = empty_list\n",
        "\n",
        "  def print_all_factors(self):\n",
        "    for i in range(0, len(self.tabular_cpds)):\n",
        "      self.tabular_cpds[i].print_factor()\n",
        "\n",
        "  def get_variables(self):\n",
        "      list_of_tuples = list(self.list_of_edges)\n",
        "      list_of_items = [item for t in list_of_tuples for item in t] \n",
        "      list_set = set(list_of_items) \n",
        "      # convert the set to the list \n",
        "      unique_list_of_vars = (list(list_set))\n",
        "      print(unique_list_of_vars)\n",
        "\n",
        "  def available_cpds(self):\n",
        "    for i in range(0, len(self.tabular_cpds)):\n",
        "      self.tabular_cpds[i].print_factor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1Ja3-jLsJgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Factor:\n",
        "  def __init__(self, indep_var, dep_vars=[]):\n",
        "    self.indep_var = indep_var\n",
        "    self.dep_vars = dep_vars\n",
        "  \n",
        "  def print_factor(self):\n",
        "    if len(self.dep_vars)>0:\n",
        "      self.dep_vars = set(self.dep_vars)\n",
        "      self.dep_vars = list(self.dep_vars)\n",
        "      self.dep_vars.sort()\n",
        "\n",
        "      dep_vars = str(self.dep_vars[0])\n",
        "      for i in range (1, len(self.dep_vars)):\n",
        "        dep_vars = dep_vars + \",\" + self.dep_vars[i]\n",
        "      print(\"P({}|{})\".format(self.indep_var, dep_vars))\n",
        "      return \"P({}|{})\".format(self.indep_var, dep_vars)\n",
        "    elif len(self.dep_vars)==0:\n",
        "      print(\"P({})\".format(self.indep_var))\n",
        "      return \"P({})\".format(self.indep_var)\n",
        "\n",
        "  def vars_in_factor(self):\n",
        "    factors = list()\n",
        "    factors.append(str(self.indep_var))\n",
        "    for i in range (0, len(self.dep_vars)):\n",
        "      factors.append(self.dep_vars[i])\n",
        "    \n",
        "    list_set = set(factors) \n",
        "    # convert the set to the list \n",
        "    unique_list_of_vars = list(list_set)\n",
        "    unique_list_of_vars.sort(reverse=False)\n",
        "\n",
        "    return unique_list_of_vars\n",
        "\n",
        "  def contains_var(self, variable):\n",
        "    if variable in self.vars_in_factor():\n",
        "      return True\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMQaLdZssKrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TabularCPD: \n",
        "  \"\"\"\n",
        "  input to initialize: \n",
        "        * variable - dependent variable\n",
        "        * variable_card - how many possible values for dependent variable \n",
        "        * values - tabular probabilities \n",
        "        * evidence - independent variable \n",
        "        * evidence_card - list of possibilities for each of the dependent variables\n",
        "  \"\"\"\n",
        "  def __init__(self, variable, variable_card, values, evidence='', evidence_card=''): \n",
        "    self.variable = variable \n",
        "    self.variable_card = variable_card\n",
        "    self.values = values\n",
        "    self.evidence = evidence\n",
        "    self.evidence_card = evidence_card\n",
        "\n",
        "\n",
        "  # Initializing factors of the CPD depending on the format (whether evidence is provided or not)\n",
        "    if len(self.evidence)>0:\n",
        "      self.factors = []\n",
        "      self.factors.append(Factor(self.variable, self.evidence))\n",
        "    \n",
        "    if len(self.evidence)==0:\n",
        "      self.factors = []\n",
        "      self.factors.append(Factor(self.variable))\n",
        "      \n",
        "    self.all_variables = []\n",
        "    self.all_variables.append(self.variable)\n",
        "    for i in range (0, len(self.evidence)):\n",
        "      self.all_variables.append(self.evidence[i])\n",
        "\n",
        "    self.truth_table = generate_truth_table(self.all_variables)\n",
        "    self.probabilities = []\n",
        "\n",
        "    for i in range(0, len(self.values)):\n",
        "      for j in range(0, len(self.values[i])):\n",
        "        self.probabilities.append(self.values[i][j])\n",
        "\n",
        "    probs = np.asarray(self.probabilities, dtype=np.float32)\n",
        "    # print(\"self.truth_table is {}\".format(self.truth_table))\n",
        "    # print(\"probs are {}\".format(probs))\n",
        "    self.truth_table['Pr'] = probs\n",
        "\n",
        "  def contains_var(self, var):\n",
        "    return var in list(self.to_truth_table().columns)\n",
        "\n",
        "  def get_factor(self):\n",
        "    \"\"\"Returns all the factors associated with a TabularCPD\"\"\"\n",
        "    return self.factors[0]\n",
        "\n",
        "  def print_factor(self):\n",
        "    self.factors[0].print_factor()\n",
        "  \n",
        "  def to_truth_table(self):\n",
        "    self.truth_table = generate_truth_table(self.all_variables)\n",
        "    # print(\"Self.truth_table is {}\".format(self.truth_table))\n",
        "    # print(\"Self.all_variables are {}\".format(self.all_variables))\n",
        "\n",
        "    self.probabilities = []\n",
        "\n",
        "    for i in range(0, len(self.values)):\n",
        "      for j in range(0, len(self.values[i])):\n",
        "        self.probabilities.append(self.values[i][j])\n",
        "\n",
        "    probs = np.asarray(self.probabilities, dtype=np.float32)\n",
        "    self.truth_table['Pr'] = probs\n",
        "\n",
        "    return self.truth_table\n",
        "\n",
        "  def marginalize(self, var_to_marginalize): \n",
        "    #marginalize by \"E\"\n",
        "    #var_to_marginalize = 'E'\n",
        "    #keeping only the values to group by that are not the variable you want to marginalize on \n",
        "    group_by_list = list(filter(lambda a: a != var_to_marginalize, self.all_variables))\n",
        "    df = self.truth_table.groupby(group_by_list).sum()\n",
        "    df = df.drop(columns=[var_to_marginalize])\n",
        "    return df \n",
        "\n",
        "  def to_pandas_df(self): \n",
        "    df = pd.DataFrame.from_records(self.values)\n",
        "    if self.evidence!='':\n",
        "      df = df.transpose()\n",
        "\n",
        "    # for every column append the name of the tabular self variable \n",
        "    cols_in_df = len(df.columns)\n",
        "    rows_in_df = len(df.index)\n",
        "\n",
        "    for i in range(0, cols_in_df):\n",
        "      df.rename(columns={ df.columns[i]: str(self.variable)+\"_\"+str(i) }, inplace = True)\n",
        "\n",
        "    df.reset_index(inplace=True)\n",
        "\n",
        "    if self.evidence!='':\n",
        "      for i in range(0, rows_in_df):\n",
        "        df.iloc[i,0] = str(self.evidence[0])+\"_\"+str(i)\n",
        "\n",
        "\n",
        "    df.set_index('index')\n",
        "\n",
        "    if self.evidence_card == [2,2]:\n",
        "      df = pd.DataFrame.from_records(self.values)\n",
        "      df = df.transpose()\n",
        "\n",
        "      # for every column append the name of the tabular self variable \n",
        "      cols_in_df = len(df.columns)\n",
        "      rows_in_df = len(df.index)\n",
        "\n",
        "      for i in range(0, cols_in_df):\n",
        "        df.rename(columns={ df.columns[i]: str(self.variable)+\"_\"+str(i) }, inplace = True)\n",
        "\n",
        "      data = df\n",
        "      df =generate_truth_table(self.evidence) \n",
        "      df['index']= str(self.evidence[0]) + \"_\" + df[str(self.evidence[0])].astype(str) + \"_\" + str(self.evidence[1]) + \"_\"+df[str(self.evidence[1])].astype(str)\n",
        "      df = df[['index']]\n",
        "      df_final = pd.concat([df, data], axis=1)\n",
        "      df_final.set_index('index')\n",
        "      return df_final.set_index('index')\n",
        "    return df.set_index('index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPmCmmps-PrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyVariableElimination:\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "    self.factors_list = self.model.tabular_cpds\n",
        "    self.final_factor = []\n",
        "    self.order = self.model.get_suggested_order()\n",
        "\n",
        "  def query(self, desired_variables, evidence=dict()):\n",
        "    self.desired_variables = desired_variables\n",
        "    self.evidence = evidence\n",
        "\n",
        "    print(\"Desired variables: {}\".format(self.desired_variables))\n",
        "    print(\"Evidence: {}\".format(self.evidence))\n",
        "\n",
        "    ##initializing order \n",
        "    if len(infer.evidence) == 0:\n",
        "      self.order = self.model.get_suggested_order()\n",
        "      for i in range(0, len(self.desired_variables)):\n",
        "        try:\n",
        "            self.order.remove(self.desired_variables[i])\n",
        "        except:\n",
        "          print(\"Please reinitialize your model\")\n",
        "      \n",
        "      print(\"My initial list of factors is \" + str(self.factors_list)+ \" of size: {}\".format(len(self.factors_list)))\n",
        "\n",
        "            # for i in range(0, len(order)):\n",
        "      for i in range(0, 5):\n",
        "        print(\"Eliminating variable: {}\".format(self.order[i]))\n",
        "        cpds_to_multiply = self.get_cpds_to_multiply(self.factors_list, self.order[i])  \n",
        "        product=recursive_multiplication(cpds_to_multiply)\n",
        "        \n",
        "        print(\"Marginalizing by:  {}\".format(self.order[i]))\n",
        "        resulting_factor = df_marginalize(product, self.order[i])\n",
        "        print(\"Appending factor: \\n {} \\n of type {}\".format(resulting_factor, type(resulting_factor)))\n",
        "        print(\"Resulting factor is :{}\")\n",
        "        # return resulting_factor\n",
        "        resulting_factor = df_to_cpd(resulting_factor)\n",
        "        self.final_factor.append(resulting_factor)\n",
        "        \n",
        "        self.delete_cpds_from_list(cpds_to_multiply)\n",
        "        if len(self.factors_list)==0:\n",
        "          print(\"answer is \")\n",
        "          resulting_factor\n",
        "          break\n",
        "        self.add_factor_to_list(resulting_factor)\n",
        "      return resulting_factor.to_truth_table()\n",
        "      # # for i in range(0, len(order)):\n",
        "      # for i in range(0, 1):\n",
        "      #   print(\"Eliminating variable: {}\".format(self.order[i]))\n",
        "      #   self.cpds_to_multiply = self.get_cpds_to_multiply(self.factors_list, self.order[i])  \n",
        "      #   product=recursive_multiplication(self.cpds_to_multiply)\n",
        "        \n",
        "      #   print(\"Marginalizing by:  {}\".format(self.order[i]))\n",
        "      #   self.resulting_factor = df_marginalize(product, self.order[i])\n",
        "      #   #print(\"Appending factor: \\n {} of type {}\".format(self.resulting_factor, type(self.resulting_factor)))\n",
        "        \n",
        "      #   print(\"Resulting factor is :{}\".format(self.resulting_factor))\n",
        "      #   # return resulting_factor\n",
        "      #   self.resulting_factor = df_to_cpd(self.resulting_factor)\n",
        "      #   self.final_factor.append(self.resulting_factor)\n",
        "        \n",
        "      #   self.delete_cpds_from_list(self.cpds_to_multiply)\n",
        "      #   if len(self.factors_list)==0:\n",
        "      #     print(\"answer is \")\n",
        "      #     df = self.resulting_factor.to_truth_table().copy()\n",
        "      #     if self.resulting_factor.to_truth_table()['Pr'].sum() != 1:\n",
        "      #       print(\"Normalizing...\")\n",
        "            \n",
        "      #       df['Pr']= df['Pr'].div(df['Pr'].sum())\n",
        "      #     print(df = self.resulting_factor.to_truth_table().cop)\n",
        "      #     break\n",
        "      #   self.add_factor_to_list(self.resulting_factor)\n",
        "      # return self.resulting_factor.to_truth_table()\n",
        "\n",
        "    if len(infer.evidence) > 0:\n",
        "      print(\"Conditonal query wanted\")\n",
        "      print(\"Choose an elimination ordering \")\n",
        "      self.order = self.model.get_suggested_order()\n",
        "      print(\"The order for elimination is: {}\".format(self.order))\n",
        "\n",
        "      print(\"\\nReplacing evidence with restriction\")\n",
        "      self.replace_evidence_with_restriction()\n",
        "      self.factors_list = self.model.tabular_cpds\n",
        "\n",
        "      self.choose_order()\n",
        "      print(\"New order is: {}, which is a list of length {}\".\\\n",
        "            format(self.order, len(self.order)))\n",
        "\n",
        "      for i in range(0, len(self.order)):\n",
        "        print(\"This is the {}th iteration...\".format(i))\n",
        "        print(\"Eliminating {}\".format(self.order[i]))\n",
        "\n",
        "        self.cpds_to_multiply = self.get_cpds_to_multiply(self.factors_list, self.order[i])  \n",
        "\n",
        "        print(\"The cpds to multiply are: \")\n",
        "        print(type(self.cpds_to_multiply))\n",
        "        for k in range(0, len(self.cpds_to_multiply)):\n",
        "          print(self.cpds_to_multiply[k].to_truth_table())\n",
        "\n",
        "        self.product=recursive_multiplication(self.cpds_to_multiply)\n",
        "        print(\"The product of recursive multiplication is \\n {} of type {}\".format(self.product, type(self.product)))\n",
        "\n",
        "        print(\"Marginalizing by {}\".format(self.order[i]))\n",
        "        self.resulting_factor = df_marginalize(self.product, self.order[i])\n",
        "\n",
        "        print(\"The resulting factor is \\n{} of type {}\".format(self.resulting_factor, type(self.resulting_factor)))\n",
        "        print(\"The factors in my list are:\\n\")\n",
        "        for j in range(0, len(self.factors_list)):\n",
        "          print(self.factors_list[j].to_truth_table())\n",
        " \n",
        "        print(\"Resulting factor is :\\n {}\".format(self.resulting_factor))\n",
        "        self.resulting_factor = df_to_cpd(self.resulting_factor)\n",
        "\n",
        "        print(\"Resulting factor after converting to cpd is :\\n {}\".format(self.resulting_factor.to_truth_table()))\n",
        "\n",
        "\n",
        "        if self.resulting_factor.to_truth_table()['Pr'].sum() == self.resulting_factor.to_truth_table()['Pr'].count(): \n",
        "          print(\"This resulting factor is irrelevant, so won't get appended to self.factors_list\")\n",
        "        \n",
        "\n",
        "        self.delete_cpds_from_list(self.cpds_to_multiply)\n",
        "\n",
        "        df = self.resulting_factor.to_truth_table().copy()\n",
        "\n",
        "        if len(self.factors_list)==0:\n",
        "          print(\"answer is \")\n",
        "          df = self.resulting_factor.to_truth_table().copy()\n",
        "          if self.resulting_factor.to_truth_table()['Pr'].sum() != 1:\n",
        "            print(\"Normalizing...\")\n",
        "            df['Pr']= df['Pr'].div(df['Pr'].sum())\n",
        "            print(df)\n",
        "            return df\n",
        "          break\n",
        "\n",
        "        if self.resulting_factor.to_truth_table()['Pr'].sum() != self.resulting_factor.to_truth_table()['Pr'].count(): \n",
        "          print(\"Factor is not irrelevant.\\n\")\n",
        "          self.add_factor_to_list(self.resulting_factor)\n",
        "          #return self.resulting_factor.to_truth_table()\n",
        "        \n",
        "        self.remove_irrelevant_factors()\n",
        "\n",
        "      #Factors left that have to do with the variable that we want \n",
        "      self.product =recursive_multiplication(self.factors_list)\n",
        "      self.resulting_factor = df_to_cpd(self.product)\n",
        "      print(\"answer is \")\n",
        "      df = self.resulting_factor.to_truth_table().copy()\n",
        "      if self.resulting_factor.to_truth_table()['Pr'].sum() != 1:\n",
        "        print(\"Normalizing...\")\n",
        "        df['Pr']= df['Pr'].div(df['Pr'].sum())\n",
        "        print(df)\n",
        "        return df\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "  def remove_irrelevant_factors(self):\n",
        "    print(\"self.factors_list before removing irrelevant factors is \")\n",
        "    for i in range(0, len(self.factors_list)):\n",
        "      print(self.factors_list[i].to_truth_table())\n",
        "\n",
        "    indices_to_pop = []\n",
        "    for i in range(0, len(self.factors_list)):\n",
        "      if self.factors_list[i].to_truth_table()['Pr'].sum() == self.factors_list[i].to_truth_table()['Pr'].count():\n",
        "        # print(\"adding {}\".format(i))\n",
        "        indices_to_pop.append(i)\n",
        "\n",
        "    indices_to_pop\n",
        "    for j in range(0, len(indices_to_pop)):\n",
        "      self.factors_list.pop(indices_to_pop[j])\n",
        "\n",
        "    return self.factors_list\n",
        "\n",
        "  def choose_order(self):\n",
        "    print(\"desired variables\")\n",
        "    for i in range(0, len(self.desired_variables)):\n",
        "      print(self.desired_variables[i])\n",
        "      self.order.remove(self.desired_variables[i])\n",
        "    for key, value in self.evidence.items() :\n",
        "      print (key, value)\n",
        "      self.order.remove(key)\n",
        "      \n",
        "\n",
        "  def get_cpds_to_multiply(self, factors_list, variable_to_eliminate):\n",
        "    \"\"\"\n",
        "    Input: A list of factors for the model and the variable of interest\n",
        "    Output: Returns all the factors in the list that are related to the variable of interest\n",
        "    \"\"\"\n",
        "    current_variable = variable_to_eliminate\n",
        "    cpds_to_multiply = []\n",
        "    for i in range(0, len(self.model.tabular_cpds)):\n",
        "      if isinstance(self.model.tabular_cpds[i], TabularCPD):\n",
        "        if self.model.tabular_cpds[i].get_factor().contains_var(current_variable):\n",
        "          cpds_to_multiply.append(self.model.tabular_cpds[i])\n",
        "    ##see if dataframe contains a variable and add it to the cpds_to_multiply list\n",
        "      elif not isinstance(self.model.tabular_cpds[i], TabularCPD):\n",
        "        df_vars = list(self.model.tabular_cpds[i].columns)\n",
        "        if current_variable in df_vars: \n",
        "          cpds_to_multiply.append(self.model.tabular_cpds[i])\n",
        "    print(\"Multiplying:...\")\n",
        "    for i in range (0, len(cpds_to_multiply)):\n",
        "      if isinstance(cpds_to_multiply[i], TabularCPD):\n",
        "        cpds_to_multiply[i].print_factor()\n",
        "      if isinstance(cpds_to_multiply[i], pd.DataFrame):\n",
        "        print(cpds_to_multiply[i])\n",
        "\n",
        "    return cpds_to_multiply\n",
        "\n",
        "  def delete_cpds_from_list(self, cpds_to_multiply):\n",
        "    for i in range(0, len(cpds_to_multiply)):\n",
        "      print(\"List size of cpds_to_multiply is {}\".format(len(cpds_to_multiply)))\n",
        "    # if it's a cpd, remove it from the list \n",
        "      if isinstance(cpds_to_multiply[i], TabularCPD):\n",
        "        print(\"Removing from self.factors_list:\")\n",
        "        cpds_to_multiply[i].print_factor()\n",
        "        self.factors_list.remove(cpds_to_multiply[i])\n",
        "      #if it's a data frame, find the equivalent one in the factors list and pop it   \n",
        "      if isinstance(cpds_to_multiply[i], pd.DataFrame):\n",
        "        self.factors_list = delete_df_from_list(self.factors_list, cpds_to_multiply[i])\n",
        "\n",
        "  def add_factor_to_list(self, resulting_factor):\n",
        "    print(\"List size of self.factors_list is {}\".format(len(self.factors_list)))\n",
        "    print(\"There are {} Factors left in self.factors_list \".format(len(self.factors_list)))\n",
        "    for i in range(0, len(self.factors_list)):\n",
        "      # print(self.factors_list[i])\n",
        "      print(self.factors_list[i].to_truth_table())\n",
        "\n",
        "    print(\"Adding new factor to list\")\n",
        "    print(resulting_factor.to_truth_table())\n",
        "    self.factors_list.append(resulting_factor)\n",
        "    self.final_factor.append(resulting_factor)\n",
        "\n",
        "    print(\"There are {} Factors left in self.factors_list\".format(len(self.factors_list)))\n",
        "    for i in range(0, len(self.factors_list)):\n",
        "      # print(self.factors_list[i])\n",
        "      print(self.factors_list[i].to_truth_table())\n",
        "\n",
        "  def replace_evidence_with_restriction(self):\n",
        "      for i in range(0, len(list(self.evidence.keys()))):\n",
        "        evidence = list(self.evidence.keys())[i]\n",
        "        print(\"Evidence is {}\".format(evidence))\n",
        "        evidence_value = list(self.evidence.values())[i]\n",
        "        print(\"Evidence value is {} \".format(evidence_value))\n",
        "        for i in range(0, len(self.model.tabular_cpds)):\n",
        "          #print(self.model.tabular_cpds[i].get_factor().contains_var(evidence))\n",
        "          #self.model.tabular_cpds[i].print_factor()\n",
        "          if self.model.tabular_cpds[i].get_factor().contains_var(evidence):\n",
        "            df = self.model.tabular_cpds[i].to_truth_table()\n",
        "            #print(\"New factor after replacing evidence {} with value  {} is:\".format(evidence, evidence_value))\n",
        "            #print(df[df[evidence]==evidence_value])\n",
        "            #print(\"cpd representation of that is: \\n\")\n",
        "            #print(df_to_cpd(df[df[evidence]==evidence_value]).to_truth_table())\n",
        "            self.new_cpd = df_to_cpd(df[df[evidence]==evidence_value])\n",
        "            self.new_df = df[df[evidence]==evidence_value]\n",
        "            self.model.tabular_cpds[i] = df_to_cpd(df[df[evidence]==evidence_value])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLaYg0-MLSVM",
        "colab_type": "text"
      },
      "source": [
        "### Query 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOHbGAepSiV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MyBayesianModel([('S1', 'O1'), ('S1', 'S2'), ('S2', 'O2'), ('S2', 'S3'), ('S3', 'O3')])\n",
        "cpd_s1 = TabularCPD(variable='S1', variable_card=2, values=[[1,0]])\n",
        "cpd_s2 = TabularCPD(variable='S2', variable_card=2,\n",
        "                   values=[[0.8, 0],\n",
        "                           [0.2, 1]],\n",
        "                   evidence=['S1'],\n",
        "                   evidence_card=[2])\n",
        "cpd_s3 = TabularCPD(variable='S3', variable_card=2,\n",
        "                   values=[[0.8, 0],\n",
        "                           [0.2, 1]],\n",
        "                   evidence=['S2'],\n",
        "                   evidence_card=[2])\n",
        "\n",
        "cpd_o1 = TabularCPD(variable='O1', variable_card=2,\n",
        "                   values=[[0.5, 0],\n",
        "                           [0.5, 1]],\n",
        "                   evidence=['S1'],\n",
        "                   evidence_card=[2])\n",
        "\n",
        "cpd_o2 = TabularCPD(variable='O2', variable_card=2,\n",
        "                   values=[[0.5, 0],\n",
        "                           [0.5, 1]],\n",
        "                   evidence=['S2'],\n",
        "                   evidence_card=[2])\n",
        "\n",
        "\n",
        "cpd_o3 = TabularCPD(variable='O3', variable_card=2,\n",
        "                   values=[[0.5, 0],\n",
        "                           [0.5, 1]],\n",
        "                   evidence=['S3'],\n",
        "                   evidence_card=[2])\n",
        "\n",
        "model.add_cpds([cpd_s1, cpd_s2, cpd_s3, cpd_o1, cpd_o2, cpd_o3])\n",
        "\n",
        "# infer = MyVariableElimination(model)\n",
        "# df = infer.query(['S3'], {'O2':1})\n",
        "# df \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7yT1HNtZ8i8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GibbsInference:\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "    self.factors_list = self.model.tabular_cpds\n",
        "    self.order = []\n",
        "    \n",
        "    \n",
        "    self.all_vars = self.get_all_model_vars()\n",
        "    self.sort_all_vars()\n",
        "\n",
        "    # self.time_table = pd.DataFrame(0, columns=self.all_vars, index=range(0))\n",
        "    \n",
        "    # self.non_evidence_var = self.all_vars[0]  \n",
        "\n",
        "    # self.get_samples()\n",
        "\n",
        "    # self.get_restriction_vars()\n",
        "\n",
        "    # self.get_cpds_to_multiply()\n",
        "    # self.get_numerator_factors_v2()\n",
        "\n",
        "    # self.numerator = recursive_multiplication(self.numerator_factors)\n",
        "    # self.numerator = df_normalize(self.numerator)\n",
        "    # self.numerator_sample_0 = sample_value_from_simple_df(self.numerator)\n",
        "\n",
        "  def get_all_model_vars(self):\n",
        "    all_model_vars=[]\n",
        "    for i in range(0, len(self.model.tabular_cpds)):\n",
        "      all_model_vars.append(self.model.tabular_cpds[i].all_variables)\n",
        "\n",
        "    all_model_vars = [val for sublist in all_model_vars for val in sublist]\n",
        "    return list(set(all_model_vars))\n",
        "\n",
        "\n",
        "  def query(self, num_iterations, desired_variables, evidence=dict()):\n",
        "    self.desired_variables = desired_variables\n",
        "    self.evidence = evidence\n",
        "\n",
        "    print(\"Desired variables: {}\".format(self.desired_variables))\n",
        "    print(\"Evidence: {}\".format(self.evidence))\n",
        "\n",
        "    print(\"Factors available for this model are \")\n",
        "    for i in range(0, len(infer.model.tabular_cpds)):\n",
        "      print(infer.model.tabular_cpds[i].to_truth_table())\n",
        "    print(\"Replacing evidence with restriction in tabular cpds\")\n",
        "    self.replace_evidence_with_restriction()\n",
        "\n",
        "    print(\"Factors after replacing evidence with restriction \")\n",
        "    for i in range(0, len(infer.model.tabular_cpds)):\n",
        "      print(infer.model.tabular_cpds[i].to_truth_table())\n",
        "\n",
        "   \n",
        "    self.vars_to_sample= self.get_all_model_vars()\n",
        "    self.vars_to_sample.sort(reverse=True)\n",
        "    print(\"Variables to sample are: {}\".format(self.vars_to_sample))\n",
        "\n",
        "    \n",
        "    self.order = self.get_suggested_order()\n",
        "    print(\"Suggested order for forward sampling is {}:\".format(self.order))\n",
        "\n",
        "    self.samples = self.get_samples_v2(self.order, self.model.tabular_cpds.copy())\n",
        "    print(\"Sample values for first round is {}:\".format(self.samples))\n",
        "\n",
        "    self.initial_state = self.get_initial_state()\n",
        "    #print(\"Initial state is {}:\".format(self.initial_state))\n",
        "\n",
        "    self.current_dict = self.samples.copy()\n",
        "    total_list_of_dicts = []\n",
        "    for j in range(0, num_iterations):\n",
        "      list_of_dicts = []\n",
        "      for i in range(0, len(self.order)):\n",
        "        current_var = self.order[i]\n",
        "        \n",
        "        sample_value =self.market_blanket_sample(current_var, self.model.tabular_cpds, self.current_dict)\n",
        "        #print(\"Sampling... {} | {} = {}\".format(current_var, self.current_dict, sample_value))\n",
        "        self.current_dict[current_var]= sample_value\n",
        "        list_of_dicts.append(self.current_dict.copy())\n",
        "      total_list_of_dicts.append(list_of_dicts[len(self.order)-1])\n",
        "\n",
        "    query_result = list_of_dicts_to_df(total_list_of_dicts)\n",
        "    return query_result[self.order]  \n",
        "\n",
        "  def replace_evidence_with_restriction(self):\n",
        "    for i in range(0, len(list(self.evidence.keys()))):\n",
        "        evidence = list(self.evidence.keys())[i]\n",
        "        print(\"Evidence is {}\".format(evidence))\n",
        "        evidence_value = list(self.evidence.values())[i]\n",
        "        print(\"Evidence value is {} \".format(evidence_value))\n",
        "        for i in range(0, len(self.model.tabular_cpds)):\n",
        "          print(self.model.tabular_cpds[i].get_factor().contains_var(evidence))\n",
        "          self.model.tabular_cpds[i].print_factor()\n",
        "          if self.model.tabular_cpds[i].get_factor().contains_var(evidence):\n",
        "            df = self.model.tabular_cpds[i].to_truth_table()\n",
        "            print(\"New factor after replacing evidence {} with value  {} is:\".format(evidence, evidence_value))\n",
        "            print(df[df[evidence]==evidence_value])\n",
        "            print(\"cpd representation of that is: \\n\")\n",
        "            print(df_to_cpd(df[df[evidence]==evidence_value]).to_truth_table())\n",
        "            self.new_cpd = df_to_cpd(df[df[evidence]==evidence_value])\n",
        "            self.new_df = df[df[evidence]==evidence_value]\n",
        "            self.model.tabular_cpds[i] = df_to_cpd(df[df[evidence]==evidence_value])\n",
        "\n",
        "  def get_cpds_to_multiply(self):\n",
        "    \"\"\"\n",
        "    Input: A list of factors for the model and the variable of interest (self.non_evidence_var)\n",
        "    Output: Returns all the factors in the list that are related to the variable of interest\n",
        "    \"\"\"\n",
        "    cpds_to_multiply = []\n",
        "    for i in range(0, len(self.model.tabular_cpds)):\n",
        "      if isinstance(self.model.tabular_cpds[i], TabularCPD):\n",
        "        if self.model.tabular_cpds[i].get_factor().contains_var(self.non_evidence_var):\n",
        "          cpds_to_multiply.append(self.model.tabular_cpds[i])\n",
        "\n",
        "    ##see if dataframe contains a variable and add it to the cpds_to_multiply list\n",
        "      elif not isinstance(self.model.tabular_cpds[i], TabularCPD):\n",
        "        df_vars = list(self.model.tabular_cpds[i].columns)\n",
        "        if self.non_evidence_var in df_vars: \n",
        "          cpds_to_multiply.append(self.model.tabular_cpds[i])\n",
        "\n",
        "    print(\"Multiplying:...\")\n",
        "    for i in range (0, len(cpds_to_multiply)):\n",
        "      if isinstance(cpds_to_multiply[i], TabularCPD):\n",
        "        cpds_to_multiply[i].print_factor()\n",
        "      if isinstance(cpds_to_multiply[i], pd.DataFrame):\n",
        "        print(cpds_to_multiply[i].to_truth_table())\n",
        "\n",
        "    self.cpds_to_multiply = cpds_to_multiply\n",
        "    return cpds_to_multiply\n",
        "\n",
        "  def sort_all_vars(self):\n",
        "    print(\"Choosing a non evidence variable... \")\n",
        "    self.all_vars.sort(reverse=True)\n",
        "    \n",
        "  def get_restriction_vars(self):\n",
        "    print(\"Getting restriction variables\")\n",
        "    self.restriction_vars = self.all_vars\n",
        "    self.restriction_vars = pop_string_from_list(self.restriction_vars, self.non_evidence_var)\n",
        "    print(\"self.restriction_vars are {}\".format(self.restriction_vars))\n",
        "\n",
        "  def get_suggested_order(self):\n",
        "    list_of_edges = self.model.list_of_edges\n",
        "    list_of_edges = [list(elem) for elem in list_of_edges]\n",
        "\n",
        "    new_list_of_edges = []\n",
        "    for i in range(0, len(list_of_edges)):\n",
        "      new_list_of_edges.append(list_of_edges[i][::-1])\n",
        "    new_list_of_edges \n",
        "\n",
        "    data = construct_trees(new_list_of_edges)\n",
        "\n",
        "    self.traverse(data)\n",
        "\n",
        "    for i in range(0, len(list(self.evidence.keys()))):\n",
        "      pop_string_from_list(self.order,list(self.evidence.keys())[i])\n",
        "\n",
        "    return self.order\n",
        "  \n",
        "  def traverse(self, dictionary):\n",
        "    if dictionary: \n",
        "      list_of_vars = list(dictionary.keys())\n",
        "      #print(list_of_vars)\n",
        "      for i in range(0, len(list_of_vars)):\n",
        "        var = list_of_vars[i]\n",
        "        self.order.append(var)\n",
        "        #print(dictionary[var])\n",
        "        self.traverse(dictionary[var])\n",
        "    else: \n",
        "      return dictionary\n",
        "    \n",
        "  def get_numerator_factors(self):\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "    print(\"Getting numerator factors...\")\n",
        "    restriction_vars = list(self.restrictions_dict.keys())\n",
        "    cpds = self.cpds_to_multiply.copy()\n",
        "    for i in range(0, len(restriction_vars)):\n",
        "      for j in range(0, len(list(cpds))):\n",
        "        # print(str(list(infer.restrictions_dict.keys())[i]) + \" in \" + str(list(cpds[j].to_truth_table().columns)))\n",
        "        # print(list(infer.restrictions_dict.keys())[i] in list(infer.cpds_to_multiply[j].to_truth_table().columns))\n",
        "        if restriction_vars[i] in list(cpds[j].to_truth_table().columns):\n",
        "          # print(infer.restrictions_dict)\n",
        "          # print(cpds[j].to_truth_table())\n",
        "          # print(restriction_vars[i], infer.restrictions_dict[restriction_vars[i]])\n",
        "          df = cpds[j].to_truth_table().copy()\n",
        "          restriction_var = str(restriction_vars[i])\n",
        "          restriction_value = self.restrictions_dict[restriction_vars[i]]\n",
        "          print(\"replacing variable {} with restriction value {} in factor \\n{}\".format(restriction_var, restriction_value, cpds[j].to_truth_table()))\n",
        "          print(\"Converting the df \\n {} to cpd \".format(df))\n",
        "          print(\"The columns on this df are {}\".format(len(df.columns)))\n",
        "          df = df[df[restriction_var]== restriction_value]\n",
        "          print(\"Converting the df \\n {} to cpd \".format(df))\n",
        "          print(\"The columns on this df are {}\".format(len(df.columns)))\n",
        "          cpds[j] = df_to_cpd(df)\n",
        "          print(\"Result is {}\".format(cpds[j].to_truth_table()))\n",
        "      \n",
        "      self.numerator_factors = cpds\n",
        "\n",
        "  def get_samples_v2(self, order, cpd_list):\n",
        "    # For each variable in the desired sampling order, take a sample from the first cpd that it sees, apply that value to the remaining list of cpds \n",
        "    # try again with the next variable \n",
        "    \"\"\"\n",
        "    Input: Given a list of variables, it will go into the list of cpds of the \n",
        "          model and sample values based on the probabilities given in each cpd \n",
        "    Output: Returns a dictionary with each of the sample values \n",
        "\n",
        "    \"\"\"\n",
        "    cpd_list1 = cpd_list\n",
        "    d = dict()\n",
        "    for i in range(0, len(order)):\n",
        "      var = order[i]\n",
        "      df = self.get_dependent_cpds(var, cpd_list1)[0].to_truth_table()\n",
        "      p = df[df[var]==1]['Pr']\n",
        "      n=1\n",
        "      s = np.random.binomial(n, p, 1)\n",
        "      value = s[0]\n",
        "      d[var] = value\n",
        "\n",
        "      cpd_list2 = []\n",
        "      cpd_list2 = set_cpds_to_state(cpd_list1, var, value)\n",
        "      cpd_list1 = []\n",
        "      cpd_list1 = cpd_list2\n",
        "    return d \n",
        "\n",
        "\n",
        "\n",
        "  def get_initial_state(self): \n",
        "    df = dictionary_to_df(self.samples.copy())\n",
        "    self.time_table = pd.DataFrame(0, columns=self.order, index=range(0))\n",
        "    self.time_table = pd.concat([self.time_table, df], ignore_index=True, sort=False)\n",
        "    return self.time_table\n",
        "\n",
        "  def get_samples(self):\n",
        "    print(\"Getting samples for first iteration\")\n",
        "    #Bernoulli trial on S1 to begin sampling \n",
        "    df = self.factors_list[0].to_truth_table()\n",
        "    p = df[df['S1']==1]['Pr']\n",
        "    n=1\n",
        "    s = np.random.binomial(n, p, 1)\n",
        "    self.samples = {'S1': s[0]}\n",
        "\n",
        "    s1_dependent_cpds = []\n",
        "    for i in range(0, len(self.model.tabular_cpds)):\n",
        "      if self.model.tabular_cpds[i].get_factor().contains_var(self.model.nodes[0].name):\n",
        "        s1_dependent_cpds.append(self.model.tabular_cpds[i])\n",
        "        #print (model.tabular_cpds[i].to_truth_table() )\n",
        "        #print(\"contains variable {}\".format(self.model.nodes[0].name))\n",
        "    s1_dependent_cpds\n",
        "\n",
        "\n",
        "    s1_dependent_cpds_replaced = []\n",
        "    for i in range(1, len(s1_dependent_cpds)):\n",
        "      s1_dependent_cpds_replaced.append(replace_cpd_with_restriction(s1_dependent_cpds[i], 'S1', 0))\n",
        "\n",
        "\n",
        "    # Generating samples of variables that depend on s1 \n",
        "    for i in range(0, len(s1_dependent_cpds_replaced)):\n",
        "      df = s1_dependent_cpds_replaced[i]\n",
        "      var = pop_string_from_list(list(df.columns), 'Pr')[0]\n",
        "      print(\"adding sample for var= {}\".format(var))\n",
        "      n=1\n",
        "      p = float(df[df[var]==1]['Pr'])\n",
        "      s = np.random.binomial(n, p, 1)\n",
        "      print(var, s[0])\n",
        "      self.samples.update( {var : s[0]} )\n",
        "      # self.samples.append((var, s[0]))\n",
        "      # self.samples = list(set(self.samples))\n",
        "      # print(self.samples)\n",
        "\n",
        "    # getting cpds that are dependent on s2 \n",
        "    s2_dependent_cpds = []\n",
        "    for i in range(0, len(self.model.tabular_cpds)):\n",
        "      if self.model.tabular_cpds[i].get_factor().contains_var('S2'):\n",
        "        s2_dependent_cpds.append(self.model.tabular_cpds[i])\n",
        "        print (model.tabular_cpds[i].to_truth_table() )\n",
        "        print(\"contains variable {}\".format('S2'))\n",
        "    s2_dependent_cpds = s2_dependent_cpds[1:]\n",
        "    s2_dependent_cpds\n",
        "\n",
        "    s2_dependent_cpds_replaced = []\n",
        "    for i in range(0, len(s2_dependent_cpds)):\n",
        "      s2_dependent_cpds_replaced.append(replace_cpd_with_restriction(s2_dependent_cpds[i], 'S2', self.samples['S2']))\n",
        "    s2_dependent_cpds_replaced\n",
        "\n",
        "    # Generating samples for variables dependent on S2 \n",
        "    for i in range(0, len(s2_dependent_cpds_replaced)):\n",
        "      df = s2_dependent_cpds_replaced[i]\n",
        "      var = pop_string_from_list(list(df.columns), 'Pr')[0]\n",
        "      print(\"adding sample for var= {}\".format(var))\n",
        "      n=1\n",
        "      p = float(df[df[var]==1]['Pr'])\n",
        "      s = np.random.binomial(n, p, 1)\n",
        "      print(var, s[0])\n",
        "      self.samples.update( {var : s[0]} )\n",
        "\n",
        "\n",
        "    #Identifying variables that depend on S3  \n",
        "    s3_dependent_cpds = []\n",
        "    for i in range(0, len(self.model.tabular_cpds)):\n",
        "      if self.model.tabular_cpds[i].get_factor().contains_var('S3'):\n",
        "        s3_dependent_cpds.append(self.model.tabular_cpds[i])\n",
        "        print (model.tabular_cpds[i].to_truth_table() )\n",
        "        print(\"contains variable {}\".format('S3'))\n",
        "\n",
        "    #Replacing variables that depend on S3 with restriction of S3 \n",
        "    s3_dependent_cpds_replaced = []\n",
        "    for i in range(0, len(s3_dependent_cpds)):\n",
        "      s3_dependent_cpds_replaced.append(replace_cpd_with_restriction(s3_dependent_cpds[i], 'S3', self.samples['S3']))\n",
        "    s3_dependent_cpds_replaced\n",
        "\n",
        "    # Generating samples for variables dependent on S3 \n",
        "    for i in range(0, len(s3_dependent_cpds_replaced)):\n",
        "      df = s3_dependent_cpds_replaced[i]\n",
        "      var = pop_string_from_list(list(df.columns), 'Pr')[0]\n",
        "      print(\"adding sample for var= {}\".format(var))\n",
        "      n=1\n",
        "      p = float(df[df[var]==1]['Pr'])\n",
        "      s = np.random.binomial(n, p, 1)\n",
        "      print(var, s[0])\n",
        "      self.samples.update( {var : s[0]} )\n",
        "\n",
        "    self.restrictions_dict = self.samples\n",
        "    del self.restrictions_dict[self.non_evidence_var]\n",
        "    print(\"self.restrictions_dict = {}\".format(self.restrictions_dict))\n",
        "    return self.samples\n",
        "\n",
        "  def get_dependent_cpds(self, var, list_of_cpds):\n",
        "    dependent_cpds = []\n",
        "    for i in range(0, len(list_of_cpds)):\n",
        "      if list_of_cpds[i].get_factor().contains_var(var):\n",
        "        dependent_cpds.append(list_of_cpds[i])\n",
        "        print (list_of_cpds[i].to_truth_table() )\n",
        "        print(\"contains variable {}\".format(var))\n",
        "    return dependent_cpds\n",
        "\n",
        "  def market_blanket_sample(self, var_to_sample, list_of_cpds, initial_dict_of_evidences):\n",
        "    list_of_vars_copy = self.order.copy()\n",
        "    list_of_vars_copy = pop_string_from_list(list_of_vars_copy, var_to_sample)\n",
        "\n",
        "    list_of_dfs = cpd_list_to_df_list(list_of_cpds.copy())\n",
        "\n",
        "    dict_of_evidences_copy = update_dict_to_sample(initial_dict_of_evidences, var_to_sample)\n",
        "\n",
        "    #print(\"Restricting list of dfs {} with {}\".format(list_of_dfs, initial_dict_of_evidences))\n",
        "    # restricted_list_of_dfs = restrict_list_of_dfs(list_of_dfs, list_of_vars_copy, dict_of_evidences_copy)\n",
        "    \n",
        "    sample_value = sample_var_from_list_of_dfs(restrict_list_of_dfs(list_of_dfs, list_of_vars_copy, dict_of_evidences_copy), var_to_sample)\n",
        "    print(\"Sampling... {}| {} = {}\".format(var_to_sample, dict_of_evidences_copy, sample_value))\n",
        "    return sample_value\n",
        "\n",
        "  def get_numerator_factors_v2(self):\n",
        "    replaced_cpds= []\n",
        "    for i in range(0, len(list(self.restrictions_dict.keys()))):\n",
        "      print(\"There are {} cpds to multiply\".format(len(self.cpds_to_multiply)))\n",
        "      for j in range(0, len(self.cpds_to_multiply)):\n",
        "        column_name = list(self.restrictions_dict.keys())[i]\n",
        "        restriction_value = self.restrictions_dict[column_name]\n",
        "        print(\"Replacing {} with restriction_value {}\".format(column_name, restriction_value))\n",
        "        if column_name in self.cpds_to_multiply[j].to_truth_table().columns: \n",
        "          print(\"Replacing {} with restriction_value {}\".format(column_name, restriction_value))\n",
        "          answer = replace_cpd_with_restriction(self.cpds_to_multiply[j], column_name, restriction_value)\n",
        "          replaced_cpds.append(answer)\n",
        "    replaced_cpds\n",
        "    self.numerator_factors = replaced_cpds\n",
        "    return self.numerator_factors\n",
        "            \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D-yrAx0_bhI",
        "colab_type": "code",
        "outputId": "94ca81ff-809f-4a1c-9691-a44df21a6c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "infer = GibbsInference(model)\n",
        "# infer.desired_variables = ['S3']\n",
        "# infer.evidence = {'O2':1}\n",
        "# infer.query(10, ['S3'], {'O2':1})\n",
        "df = infer.query(100, ['S3'], {'O1':1, 'O2':0, 'O3':1})\n",
        "# infer.query(10, ['S3'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Choosing a non evidence variable... \n",
            "Desired variables: ['S3']\n",
            "Evidence: {'O1': 1, 'O2': 0, 'O3': 1}\n",
            "Factors available for this model are \n",
            "   S1   Pr\n",
            "0   0  1.0\n",
            "1   1  0.0\n",
            "   S2  S1   Pr\n",
            "0   0   0  0.8\n",
            "1   0   1  0.0\n",
            "2   1   0  0.2\n",
            "3   1   1  1.0\n",
            "   S3  S2   Pr\n",
            "0   0   0  0.8\n",
            "1   0   1  0.0\n",
            "2   1   0  0.2\n",
            "3   1   1  1.0\n",
            "   S1   Pr\n",
            "0   0  0.5\n",
            "1   1  1.0\n",
            "   S2   Pr\n",
            "0   0  0.5\n",
            "1   1  0.0\n",
            "   S3   Pr\n",
            "0   0  0.5\n",
            "1   1  1.0\n",
            "Replacing evidence with restriction in tabular cpds\n",
            "Evidence is O1\n",
            "Evidence value is 1 \n",
            "False\n",
            "P(S1)\n",
            "False\n",
            "P(S2|S1)\n",
            "False\n",
            "P(S3|S2)\n",
            "False\n",
            "P(S1)\n",
            "False\n",
            "P(S2)\n",
            "False\n",
            "P(S3)\n",
            "Evidence is O2\n",
            "Evidence value is 0 \n",
            "False\n",
            "P(S1)\n",
            "False\n",
            "P(S2|S1)\n",
            "False\n",
            "P(S3|S2)\n",
            "False\n",
            "P(S1)\n",
            "False\n",
            "P(S2)\n",
            "False\n",
            "P(S3)\n",
            "Evidence is O3\n",
            "Evidence value is 1 \n",
            "False\n",
            "P(S1)\n",
            "False\n",
            "P(S2|S1)\n",
            "False\n",
            "P(S3|S2)\n",
            "False\n",
            "P(S1)\n",
            "False\n",
            "P(S2)\n",
            "False\n",
            "P(S3)\n",
            "Factors after replacing evidence with restriction \n",
            "   S1   Pr\n",
            "0   0  1.0\n",
            "1   1  0.0\n",
            "   S2  S1   Pr\n",
            "0   0   0  0.8\n",
            "1   0   1  0.0\n",
            "2   1   0  0.2\n",
            "3   1   1  1.0\n",
            "   S3  S2   Pr\n",
            "0   0   0  0.8\n",
            "1   0   1  0.0\n",
            "2   1   0  0.2\n",
            "3   1   1  1.0\n",
            "   S1   Pr\n",
            "0   0  0.5\n",
            "1   1  1.0\n",
            "   S2   Pr\n",
            "0   0  0.5\n",
            "1   1  0.0\n",
            "   S3   Pr\n",
            "0   0  0.5\n",
            "1   1  1.0\n",
            "Variables to sample are: ['S3', 'S2', 'S1']\n",
            "Suggested order for forward sampling is ['S1', 'S2', 'S3']:\n",
            "   S1   Pr\n",
            "0   0  1.0\n",
            "1   1  0.0\n",
            "contains variable S1\n",
            "   S2  S1   Pr\n",
            "0   0   0  0.8\n",
            "1   0   1  0.0\n",
            "2   1   0  0.2\n",
            "3   1   1  1.0\n",
            "contains variable S1\n",
            "   S1   Pr\n",
            "0   0  0.5\n",
            "1   1  1.0\n",
            "contains variable S1\n",
            "   S2  S1   Pr\n",
            "0   0   0  0.8\n",
            "1   0   1  0.0\n",
            "2   1   0  0.2\n",
            "3   1   1  1.0\n",
            "i:1\n",
            "0\n",
            "S2\n",
            "0    0\n",
            "2    1\n",
            "Name: S2, dtype: int64\n",
            "1\n",
            "S1\n",
            "0    0\n",
            "2    0\n",
            "Name: S1, dtype: int64\n",
            "0\n",
            "S2\n",
            "0    0\n",
            "2    1\n",
            "Name: S2, dtype: int64\n",
            "   S3  S2   Pr\n",
            "0   0   0  0.8\n",
            "1   0   1  0.0\n",
            "2   1   0  0.2\n",
            "3   1   1  1.0\n",
            "   S2   Pr\n",
            "0   0  0.8\n",
            "1   1  0.2\n",
            "contains variable S2\n",
            "   S3  S2   Pr\n",
            "0   0   0  0.8\n",
            "1   0   1  0.0\n",
            "2   1   0  0.2\n",
            "3   1   1  1.0\n",
            "contains variable S2\n",
            "   S2   Pr\n",
            "0   0  0.5\n",
            "1   1  0.0\n",
            "contains variable S2\n",
            "   S3  S2   Pr\n",
            "0   0   0  0.8\n",
            "1   0   1  0.0\n",
            "2   1   0  0.2\n",
            "3   1   1  1.0\n",
            "i:2\n",
            "0\n",
            "S3\n",
            "0    0\n",
            "2    1\n",
            "Name: S3, dtype: int64\n",
            "1\n",
            "S2\n",
            "0    0\n",
            "2    0\n",
            "Name: S2, dtype: int64\n",
            "0\n",
            "S3\n",
            "0    0\n",
            "2    1\n",
            "Name: S3, dtype: int64\n",
            "   S3   Pr\n",
            "0   0  0.8\n",
            "1   1  0.2\n",
            "contains variable S3\n",
            "   S3   Pr\n",
            "0   0  0.5\n",
            "1   1  1.0\n",
            "contains variable S3\n",
            "Sample values for first round is {'S1': 0, 'S2': 0, 'S3': 0}:\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 1\n",
            "Sampling... S3| {'S1': 0, 'S2': 1} = 1\n",
            "Sampling... S1| {'S2': 1, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 1\n",
            "Sampling... S1| {'S2': 0, 'S3': 1} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 1} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n",
            "Sampling... S1| {'S2': 0, 'S3': 0} = 0\n",
            "Sampling... S2| {'S1': 0, 'S3': 0} = 0\n",
            "Sampling... S3| {'S1': 0, 'S2': 0} = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2GbwHGKbtBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "5450a442-46b9-4ec6-d83b-d2fd2d5eb274"
      },
      "source": [
        "plot_probs_on_variable('S3', 1, df, 20)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Pr[0]': 0.54, 'Pr[1]': 0.46}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  keepdims=keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr_raszCymPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDzWndCEC2qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_probs_on_variable(var, binary_value, df, start_val):\n",
        "  list_of_probs = []\n",
        "  total_dfs = df\n",
        "  result = { 'Pr[0]': df[var].value_counts()[0]/ len(df), 'Pr[1]':df[var].value_counts()[1]/ len(df)}\n",
        "  print(result)\n",
        "  for i in range(0, total_dfs.shape[0]):\n",
        "    df = total_dfs[infer.order][:i]\n",
        "    list_of_probs.append(list(df[df[var]==binary_value].count()/ df.count())[0])\n",
        "  results = []\n",
        "  for i in range(start_val, len(list_of_probs)):\n",
        "    results.append((list_of_probs[i], mean_confidence_interval(list_of_probs[start_val-1:i])))\n",
        "  \n",
        "  mins = []\n",
        "  maxs = []\n",
        "  means = []\n",
        "  for i in range(0, len(results)):\n",
        "    mins.append(results[i][1][0])\n",
        "    maxs.append(results[i][1][2])\n",
        "    means.append(results[i][1][1])\n",
        "  plt.plot(list_of_probs[start_val:])\n",
        "  plt.plot(mins)\n",
        "  plt.plot(maxs)\n",
        "  plt.plot(means)\n",
        "  return "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDbEVM7tT_x1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query_result[['S3']].std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_vOK8EIS-LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var = 'S3'\n",
        "binary_value =0\n",
        "df = query_result\n",
        "plot_probs_on_variable(var, binary_value, df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVslF7mzRYay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var = 'S3'\n",
        "binary_value =1\n",
        "df = query_result\n",
        "plot_probs_on_variable(var, binary_value, df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CcIHP7SObDc",
        "colab_type": "text"
      },
      "source": [
        "### **Using My Variable Elimination**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tobc_wKOFeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = MyBayesianModel([('S1', 'O1'), ('S1', 'S2'), ('S2', 'O2'), ('S2', 'S3'), ('S3', 'O3')])\n",
        "# cpd_s1 = TabularCPD(variable='S1', variable_card=2, values=[[1,0]])\n",
        "# cpd_s2 = TabularCPD(variable='S2', variable_card=2,\n",
        "#                    values=[[0.8, 0],\n",
        "#                            [0.2, 1]],\n",
        "#                    evidence=['S1'],\n",
        "#                    evidence_card=[2])\n",
        "# cpd_s3 = TabularCPD(variable='S3', variable_card=2,\n",
        "#                    values=[[0.8, 0],\n",
        "#                            [0.2, 1]],\n",
        "#                    evidence=['S2'],\n",
        "#                    evidence_card=[2])\n",
        "\n",
        "# cpd_o1 = TabularCPD(variable='O1', variable_card=2,\n",
        "#                    values=[[0.5, 0],\n",
        "#                            [0.5, 1]],\n",
        "#                    evidence=['S1'],\n",
        "#                    evidence_card=[2])\n",
        "\n",
        "# cpd_o2 = TabularCPD(variable='O2', variable_card=2,\n",
        "#                    values=[[0.5, 0],\n",
        "#                            [0.5, 1]],\n",
        "#                    evidence=['S2'],\n",
        "#                    evidence_card=[2])\n",
        "\n",
        "\n",
        "# cpd_o3 = TabularCPD(variable='O3', variable_card=2,\n",
        "#                    values=[[0.5, 0],\n",
        "#                            [0.5, 1]],\n",
        "#                    evidence=['S3'],\n",
        "#                    evidence_card=[2])\n",
        "\n",
        "# model.add_cpds([cpd_s1, cpd_s2, cpd_s3, cpd_o1, cpd_o2, cpd_o3])\n",
        "\n",
        "# infer = MyVariableElimination(model)\n",
        "# df = infer.query(['S3'], {'O2':1})\n",
        "# df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTQ3RskYOqVj",
        "colab_type": "text"
      },
      "source": [
        "### **Using PGMPY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46AWU_frORTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install pgmpy\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "model = BayesianModel([('S1', 'O1'), ('S1', 'S2'), ('S2', 'O2'), ('S2', 'S3'), ('S3', 'O3')])\n",
        "\n",
        "cpd_s1 = TabularCPD(variable='S1', variable_card=2, values=[[1,0]])\n",
        "cpd_s2 = TabularCPD(variable='S2', variable_card=2,\n",
        "                   values=[[0.8, 0],\n",
        "                           [0.2, 1]],\n",
        "                   evidence=['S1'],\n",
        "                   evidence_card=[2])\n",
        "cpd_s3 = TabularCPD(variable='S3', variable_card=2,\n",
        "                   values=[[0.8, 0],\n",
        "                           [0.2, 1]],\n",
        "                   evidence=['S2'],\n",
        "                   evidence_card=[2])\n",
        "\n",
        "cpd_o1 = TabularCPD(variable='O1', variable_card=2,\n",
        "                   values=[[0.5, 0],\n",
        "                           [0.5, 1]],\n",
        "                   evidence=['S1'],\n",
        "                   evidence_card=[2])\n",
        "\n",
        "cpd_o2 = TabularCPD(variable='O2', variable_card=2,\n",
        "                   values=[[0.5, 0],\n",
        "                           [0.5, 1]],\n",
        "                   evidence=['S2'],\n",
        "                   evidence_card=[2])\n",
        "\n",
        "\n",
        "cpd_o3 = TabularCPD(variable='O3', variable_card=2,\n",
        "                   values=[[0.5, 0],\n",
        "                           [0.5, 1]],\n",
        "                   evidence=['S3'],\n",
        "                   evidence_card=[2])\n",
        "\n",
        "model.add_cpds(cpd_s1, cpd_s2, cpd_s3, cpd_o1, cpd_o2, cpd_o3)\n",
        "infer2 = VariableElimination(model)\n",
        "\n",
        "\n",
        "print(infer2.query(['S3'], evidence={'O1':1, 'O2':0, 'O3':1}))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY1lPZqiOweQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}